# AnalisisB2
## 1. Algoritmos y Probabilidad

Los algoritmos no siempre siguen caminos deterministas y predecibles. En el mundo de la computaciÃ³n moderna, existen enfoques en los que la incertidumbre y el azar juegan un papel central: los **algoritmos probabilÃ­sticos**.

## Â¿QuÃ© son los algoritmos probabilÃ­sticos?

Se trata de algoritmos que incorporan el azar como parte de su funcionamiento. A diferencia de los algoritmos deterministas, que producen el mismo resultado para una entrada dada, los algoritmos probabilÃ­sticos pueden ofrecer distintos resultados en ejecuciones diferentes, incluso si la entrada no cambia.

Esto se debe a que estos algoritmos hacen uso de generadores de nÃºmeros aleatorios para tomar decisiones durante su ejecuciÃ³n.

## Â¿Por quÃ© utilizar la probabilidad en algoritmos?

Los beneficios de emplear algoritmos probabilÃ­sticos emergen principalmente cuando se enfrentan los siguientes escenarios:

- **Alta complejidad computacional**: cuando una soluciÃ³n exacta requiere demasiado tiempo o recursos.
- **Problemas mal definidos o dinÃ¡micos**: donde los datos cambian o son ruidosos.
- **Necesidad de respuestas rÃ¡pidas**: cuando una soluciÃ³n buena es preferible a una soluciÃ³n Ã³ptima que llegue demasiado tarde.
- **Ausencia de mÃ©todos deterministas eficientes**: en ciertos dominios, simplemente no existen algoritmos deterministas prÃ¡cticos.

## ClasificaciÃ³n de algoritmos probabilÃ­sticos

Los algoritmos basados en probabilidad se dividen, principalmente, en dos categorÃ­as:

### ðŸ”¹ Algoritmos de tipo Monte Carlo

- **Resultado**: No siempre es correcto.
- **Ventaja**: Tienen tiempos de ejecuciÃ³n limitados y controlables.
- **Uso tÃ­pico**: Problemas donde se puede aceptar cierto margen de error a cambio de mayor velocidad.
- **Ejemplo**: Algoritmos para verificar si un nÃºmero es primo.

### ðŸ”¹ Algoritmos de tipo Las Vegas

- **Resultado**: Siempre correcto.
- **Inconveniente**: El tiempo de ejecuciÃ³n es impredecible.
- **Uso tÃ­pico**: Problemas donde no se puede permitir un resultado errÃ³neo, pero sÃ­ variar el tiempo que se tarda en obtenerlo.
- **Ejemplo**: QuickSort con pivote aleatorio.

## Aplicaciones prÃ¡cticas

El uso de algoritmos probabilÃ­sticos se extiende a muchos campos:

- **Seguridad informÃ¡tica y criptografÃ­a**: generaciÃ³n de claves, protocolos seguros.
- **SimulaciÃ³n y modelado**: mÃ©todos de Monte Carlo para simulaciones fÃ­sicas o financieras.
- **BiologÃ­a computacional**: bÃºsqueda de secuencias genÃ©ticas.
- **GrÃ¡ficos por computadora**: para simular fenÃ³menos como el comportamiento de la luz.
- **Inteligencia artificial**: aprendizaje reforzado y redes bayesianas.

## Un ejemplo prÃ¡ctico: el dilema de la bÃºsqueda

Imagina tener una base de datos no ordenada con millones de entradas. Un algoritmo determinista tendrÃ­a que revisar cada elemento uno por uno. En cambio, un enfoque probabilÃ­stico podrÃ­a hacer selecciones aleatorias y, con cierta probabilidad, encontrar la entrada buscada mÃ¡s rÃ¡pido, especialmente si el valor aparece mÃºltiples veces.

## Consideraciones importantes

### âœ… Ventajas

- Soluciones rÃ¡pidas en promedio.
- FÃ¡ciles de implementar.
- Eficaces para problemas complejos o inciertos.

### âš ï¸ Desventajas

- Resultado no garantizado (en algunos casos).
- Dependencia de una fuente fiable de aleatoriedad.
- Dificultad para analizar el peor caso de rendimiento.

## ReflexiÃ³n final

La inclusiÃ³n de la probabilidad en el diseÃ±o de algoritmos amplÃ­a significativamente las herramientas disponibles para los desarrolladores. Aunque pueda parecer contraproducente confiar en el azar, en muchos casos esta estrategia ofrece un equilibrio ideal entre eficiencia y precisiÃ³n.

Los algoritmos probabilÃ­sticos enriquecen el panorama de paradigmas de resoluciÃ³n de problemas, y reflejan cÃ³mo la computaciÃ³n puede beneficiarse incluso de lo impredecible.

---
## 2. Paradigma: Divide y VencerÃ¡s  
## Caso aplicado: BÃºsqueda Binaria

La programaciÃ³n algorÃ­tmica cuenta con varios paradigmas poderosos para resolver problemas. Uno de los mÃ¡s conocidos es **Divide y VencerÃ¡s**, una estrategia que ha dado lugar a algunos de los algoritmos mÃ¡s eficientes. En esta ocasiÃ³n, exploraremos cÃ³mo este paradigma se aplica en la **bÃºsqueda binaria**, una tÃ©cnica fundamental en la informÃ¡tica.

## Â¿En quÃ© consiste el paradigma de Divide y VencerÃ¡s?

Este enfoque divide un problema complejo en subproblemas mÃ¡s pequeÃ±os y mÃ¡s manejables. Luego, se resuelve cada subproblema (a menudo de forma recursiva), y finalmente se combinan las soluciones parciales para obtener el resultado final.

Las tres etapas principales son:

1. **Dividir**: Separar el problema en partes.
2. **Vencer (resolver)**: Resolver cada parte por separado.
3. **Combinar**: Integrar las soluciones de las partes para formar la soluciÃ³n total.

Este patrÃ³n estÃ¡ presente en algoritmos como MergeSort, QuickSort, Fast Fourier Transform (FFT), y tambiÃ©n en **bÃºsqueda binaria**.

## Â¿QuÃ© es la BÃºsqueda Binaria?

La **bÃºsqueda binaria** es un algoritmo diseÃ±ado para buscar un elemento en una lista ordenada. En lugar de revisar todos los elementos uno por uno, el algoritmo descarta la mitad de la lista en cada paso.

### Idea bÃ¡sica

Dado un arreglo ordenado `A` y un valor `x` a buscar:

1. Se compara `x` con el elemento del medio.
2. Si son iguales, se encontrÃ³ el elemento.
3. Si `x` es menor, se repite el proceso en la mitad izquierda.
4. Si `x` es mayor, se repite en la mitad derecha.

Este proceso se repite hasta encontrar el valor o hasta que el subarreglo sea vacÃ­o.

---

## Ejemplo: Prueba de Escritorio (nuevo)

### Tupla de entrada:
```python
T = [5, 12, 18, 27, 33, 41, 60, 73, 85, 99]
x = 41
```

### Pasos del algoritmo:

1. `Inicio = 0`, `Fin = 9`  
   `Mitad = (0 + 9) // 2 = 4 â†’ T[4] = 33`  
   Como `41 > 33`, se busca a la derecha.

2. `Inicio = 5`, `Fin = 9`  
   `Mitad = (5 + 9) // 2 = 7 â†’ T[7] = 73`  
   Como `41 < 73`, se busca a la izquierda.

3. `Inicio = 5`, `Fin = 6`  
   `Mitad = (5 + 6) // 2 = 5 â†’ T[5] = 41`  
   Â¡Elemento encontrado!

### Resultado:

El elemento `x = 41` se encuentra en la **posiciÃ³n 5** del arreglo.

---


---

## Complejidad del algoritmo

- **Tiempo**: O(log n)  
- **Espacio**: O(1) (versiÃ³n iterativa) u O(log n) (versiÃ³n recursiva)

La eficiencia del algoritmo es producto del paradigma de **divide y vencerÃ¡s**, que reduce el tamaÃ±o del problema a la mitad en cada iteraciÃ³n.

## Ventajas de la bÃºsqueda binaria

- Muy rÃ¡pida en arreglos ordenados.
- FÃ¡cil de implementar.
- Ideal para grandes volÃºmenes de datos.

## Limitaciones

- Solo funciona en estructuras ordenadas.
- Requiere acceso aleatorio a los elementos (por ejemplo, en arreglos; no en listas enlazadas).
- Puede ser menos eficiente que una bÃºsqueda lineal si el conjunto es muy pequeÃ±o.

## Aplicaciones comunes

- VerificaciÃ³n rÃ¡pida de existencia en bases de datos.
- LocalizaciÃ³n de lÃ­mites o umbrales (por ejemplo, en problemas de optimizaciÃ³n).
- ImplementaciÃ³n de estructuras como Ã¡rboles de bÃºsqueda binaria (BST).
- Uso en librerÃ­as estÃ¡ndar (`binary_search` en C++, `bisect` en Python).
## ImplementaciÃ³n bÃ¡sica (Iterativa)

La bÃºsqueda binaria puede implementarse de distintas formas, pero una de las mÃ¡s comunes es el enfoque iterativo, el cual utiliza un bucle para reducir progresivamente el intervalo de bÃºsqueda.

A continuaciÃ³n, se muestra una versiÃ³n en Java que realiza esta tarea. El algoritmo parte del arreglo ordenado y compara el valor objetivo con el elemento central. Dependiendo del resultado, se descarta la mitad izquierda o derecha del arreglo, repitiendo el proceso hasta encontrar el elemento o agotar las opciones.

```java
public static int busquedaBinaria(int[] arreglo, int x) {
    int inicio = 0;
    int fin = arreglo.length - 1;

    while (inicio <= fin) {
        int mitad = (inicio + fin) / 2;

        if (arreglo[mitad] == x)
            return mitad; // Elemento encontrado
        else if (x < arreglo[mitad])
            fin = mitad - 1; // Buscar en la mitad izquierda
        else
            inicio = mitad + 1; // Buscar en la mitad derecha
    }
    return -1; // Elemento no encontrado
}
```

## ReflexiÃ³n final

La **bÃºsqueda binaria** es un claro ejemplo de cÃ³mo el paradigma de **divide y vencerÃ¡s** puede transformar una operaciÃ³n aparentemente simple como buscar un nÃºmero, en una operaciÃ³n altamente eficiente. Al reducir el espacio de bÃºsqueda a la mitad en cada paso, se consigue un rendimiento excelente en escenarios donde la rapidez es clave.

Comprender este paradigma no solo mejora nuestras habilidades de resoluciÃ³n de problemas, sino que tambiÃ©n nos brinda herramientas para diseÃ±ar algoritmos elegantes y poderosos.
---
## 3. Merge Sort â€“ Ordenamiento por Mezcla

## Â¿QuÃ© es Merge Sort?

**Merge Sort** es un algoritmo de ordenamiento que sigue el paradigma de **Divide y VencerÃ¡s**. Es eficiente, estable y garantiza un rendimiento de O(n log n) en todos los casos.

Este algoritmo divide una lista en sublistas mÃ¡s pequeÃ±as, ordena cada una de ellas y luego las combina (fusiona) en una lista final ordenada.

---

## ðŸ”§ Principio del algoritmo

1. **DivisiÃ³n**: Se divide la lista en dos mitades.
2. **Conquista**: Se ordenan recursivamente ambas mitades usando el mismo algoritmo.
3. **CombinaciÃ³n**: Se fusionan ambas mitades ordenadas en una nueva lista ordenada.

---

## RepresentaciÃ³n simplificada del algoritmo

```python
funciÃ³n mergeSort(lista):
    si longitud(lista) â‰¤ 1:
        retornar lista
    mitad = longitud(lista) / 2
    izquierda = mergeSort(lista[0:mitad])
    derecha = mergeSort(lista[mitad:])
    retornar merge(izquierda, derecha)

funciÃ³n merge(izquierda, derecha):
    resultado = []
    mientras izquierda y derecha no estÃ©n vacÃ­as:
        si izquierda[0] < derecha[0]:
            agregar izquierda[0] a resultado
            eliminar izquierda[0]
        sino:
            agregar derecha[0] a resultado
            eliminar derecha[0]
    agregar elementos restantes de izquierda y derecha a resultado
    retornar resultado
```

---

## âœ… Ventajas

- Rendimiento garantizado O(n log n)
- Estable: mantiene el orden relativo de elementos iguales
- Funciona bien con listas enlazadas
- Predecible incluso en el peor caso

## âš ï¸ Desventajas

- Requiere espacio adicional (arreglos auxiliares)
- Puede ser mÃ¡s lento que algoritmos como QuickSort para listas pequeÃ±as
- Mayor complejidad de implementaciÃ³n

---

## ðŸ“Œ Aplicaciones comunes

- Sistemas de archivos y bases de datos que requieren ordenamiento estable
- Grandes volÃºmenes de datos que no caben en memoria (ordenamiento externo)
- Algoritmos hÃ­bridos como **Timsort** (usado en Python y Java) que usan Merge Sort como parte de su lÃ³gica
- Ordenamiento en listas enlazadas

---

## ConclusiÃ³n

**Merge Sort** es un algoritmo robusto, confiable y eficiente para el ordenamiento de listas. Su estructura basada en el paradigma *Divide y VencerÃ¡s* lo hace ideal para manejar grandes volÃºmenes de datos de manera predecible.

Aunque puede no ser el mÃ¡s rÃ¡pido en todos los casos, su rendimiento consistente y su estabilidad lo convierten en una excelente opciÃ³n cuando se necesita precisiÃ³n y consistencia en el ordenamiento.

## 4. QuickSort â€“ Ordenamiento RÃ¡pido

## Â¿QuÃ© es QuickSort?

**QuickSort** es un algoritmo de ordenamiento basado en el paradigma de **Divide y VencerÃ¡s**. Se destaca por su alta eficiencia en la prÃ¡ctica y su bajo consumo de memoria.

El algoritmo selecciona un elemento como pivote y divide el arreglo en dos partes: los elementos menores al pivote y los mayores. Luego, aplica el mismo procedimiento recursivamente a ambas sublistas.

---

## Principio del algoritmo

1. **DivisiÃ³n**: Elegir un elemento como pivote.
2. **Conquista**: Reorganizar los elementos de manera que los menores al pivote queden a su izquierda y los mayores a su derecha.
3. **CombinaciÃ³n**: Aplicar recursivamente QuickSort a las dos sublistas generadas.

---

## RepresentaciÃ³n simplificada del algoritmo

```python
funciÃ³n quickSort(lista):
    si longitud(lista) â‰¤ 1:
        retornar lista
    pivote = lista[0]
    menores = [elemento para elemento en lista[1:] si elemento < pivote]
    mayores = [elemento para elemento en lista[1:] si elemento â‰¥ pivote]
    retornar quickSort(menores) + [pivote] + quickSort(mayores)

```
---

## âœ… Ventajas

- Muy eficiente en promedio: O(n log n)
- No requiere memoria adicional significativa
- Generalmente mÃ¡s rÃ¡pido que MergeSort para listas en memoria
- FÃ¡cil de implementar

## âš ï¸ Desventajas

- Peor caso O(nÂ²) si el pivote no se elige bien
- No es estable (puede cambiar el orden de elementos iguales)
- Rendimiento sensible a la elecciÃ³n del pivote

---

## ðŸ“Œ Aplicaciones comunes

- Ordenamiento de grandes arreglos en memoria
- Sistemas que priorizan velocidad sobre estabilidad
- Implementaciones de ordenamiento estÃ¡ndar en muchos lenguajes (C, Java, etc.)
- Algoritmos hÃ­bridos como introsort

---

## ConclusiÃ³n

**QuickSort** es uno de los algoritmos de ordenamiento mÃ¡s populares por su gran rendimiento promedio y bajo uso de memoria. Aunque su rendimiento puede degradarse en casos especÃ­ficos, una buena elecciÃ³n de pivote y versiones optimizadas lo hacen extremadamente Ãºtil en aplicaciones reales.
---
## 5.  Algoritmos Voraces

## Â¿QuÃ© es un Algoritmo Voraz?

Un **algoritmo voraz** (o *greedy*) es una estrategia de diseÃ±o de algoritmos que toma decisiones paso a paso, eligiendo la opciÃ³n que parece ser la mejor en ese momento sin reconsiderar decisiones anteriores.

El objetivo es construir una soluciÃ³n aproximada Ã³ptima o, en algunos casos, Ã³ptima exacta, tomando en cada paso la decisiÃ³n mÃ¡s inmediata y favorable.

---

## ðŸ”§ Principio del Algoritmo Voraz

1. Se divide el problema en etapas.
2. En cada etapa, se toma la mejor decisiÃ³n local posible.
3. No se vuelve atrÃ¡s ni se reconsideran decisiones anteriores.
4. Al final, la combinaciÃ³n de decisiones locales produce una soluciÃ³n global.

---

## RepresentaciÃ³n simplificada

```python
funciÃ³n algoritmoVoraz(problema):
    soluciÃ³n = soluciÃ³n vacÃ­a
    mientras problema no estÃ© resuelto:
        elegir la mejor opciÃ³n local disponible
        agregar esa opciÃ³n a soluciÃ³n
    retornar soluciÃ³n

```
---

## âœ… Ventajas

- FÃ¡cil de implementar.
- RÃ¡pido, generalmente con complejidad polinomial.
- Funciona bien para muchos problemas prÃ¡cticos.
- Ideal para problemas donde la elecciÃ³n local lleva a soluciÃ³n global Ã³ptima.
## âš ï¸ Desventajas

- No garantiza la soluciÃ³n Ã³ptima para todos los problemas.
- Puede ser necesario analizar cuidadosamente si el enfoque voraz es adecuado.
- Algunas soluciones requieren tÃ©cnicas mÃ¡s complejas (programaciÃ³n dinÃ¡mica, backtracking).
---

## ðŸ“Œ Aplicaciones comunes

- Problema de la mochila fraccionaria.
- Algoritmos de cÃ³digo Huffman para compresiÃ³n.
- SelecciÃ³n de actividades que no se traslapan (problema de scheduling).
- ConstrucciÃ³n de Ã¡rboles de expansiÃ³n mÃ­nima (Prim, Kruskal).
- OptimizaciÃ³n en redes y rutas.

---

## ConclusiÃ³n

Los **algoritmos voraces** son una herramienta poderosa para resolver problemas complejos de manera eficiente cuando las condiciones del problema permiten que las decisiones locales Ã³ptimas lleven a soluciones globales Ã³ptimas.

Sin embargo, su simplicidad tambiÃ©n puede ser una limitaciÃ³n, y es crucial verificar que el problema en cuestiÃ³n sea apto para esta estrategia antes de aplicarla.



